{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4cde1b",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08c340c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import adf_test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Predictor(nn.Module):\n",
    "    def __init__(self, input_size:int = 4, hidden_size: int = 24, output_size = 3, quants = [0.2, 0.5, 0.8], batch_first = True):\n",
    "        super().__init__()\n",
    "        self.quants = quants \n",
    "        self.n_quants = len(quants)\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.model = nn.Sequential(\n",
    "                                    nn.Linear(input_size, hidden_size),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(hidden_size, hidden_size),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(hidden_size, int(hidden_size/2)),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(int(hidden_size/2), output_size * self.n_quants)\n",
    "                                    )\n",
    "    def forward(self, x):\n",
    "        out =  self.model(x)\n",
    "        out_reshaped = out.reshape(-1, self.output_size, self.n_quants)\n",
    "        return out_reshaped\n",
    "\n",
    "\n",
    "def pinball_loss(preds, targets, quants):\n",
    "    loss = 0\n",
    "\n",
    "    for i, q in enumerate(quants):\n",
    "        errors = targets - preds[:, :, i]\n",
    "        loss += torch.mean(torch.max((q - 1) * errors, q * errors))\n",
    "    return loss / len(quants)\n",
    "\n",
    "\n",
    "### Predictor Class\n",
    "class Predictor:\n",
    "\n",
    "        \n",
    "    def __init__(self, iso = 'random'):\n",
    "        self.iso = iso\n",
    "        self.predictions = {}\n",
    "        self.metrics = {}\n",
    "        self.targets = ['dalmp','rtlmp','wind_power_mw']\n",
    "        self.inputs = ['system_load_forecast', 'system_solar_forecast', 'system_wind_forecast', 'outage_forecast']\n",
    "        self.model = {}\n",
    "\n",
    "    def read_train_test_data(self, train_file = 'data/train_data.parquet', test_file = 'data/test_data.parquet'):\n",
    "        self.train_data = pd.read_parquet(train_file)\n",
    "        self.test_data = pd.read_parquet(test_file)\n",
    "\n",
    "        self.train_data.to_csv('train_data.csv')\n",
    "        self.test_data.to_csv('test_data.csv')\n",
    "\n",
    "    def add_temporal_features(self, dataset: pd.DataFrame):\n",
    "        dataset['hour'] = dataset.index\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        #remove nan values\n",
    "        self.train_data = self.train_data.dropna()\n",
    "        self.test_data = self.test_data.dropna()\n",
    "\n",
    "    def separate_inputs_targets(self):\n",
    "        self.x_train = self.train_data[self.inputs]\n",
    "        self.y_train = self.train_data[self.targets]\n",
    "        self.x_test = self.test_data[self.inputs]\n",
    "    \n",
    "    def normalize_data(self):\n",
    "        #normalize the train and test data\n",
    "        self.scaler_input = StandardScaler()\n",
    "        self.scaler_target = StandardScaler()\n",
    "        self.x_train_norm = pd.DataFrame(self.scaler_input.fit_transform(self.x_train), columns= self.x_train.columns)\n",
    "        self.y_train_norm = pd.DataFrame(self.scaler_input.fit_transform(self.y_train), columns= self.y_train.columns)\n",
    "        self.x_test_norm = pd.DataFrame(self.scaler_input.fit_transform(self.x_test), columns= self.x_test.columns)\n",
    "    \n",
    "\n",
    "    def train_neural_model(self,epochs = 25, lr = 5e-5):\n",
    "        self.Neural = Neural_Predictor()\n",
    "        optimizer = torch.optim.Adam(self.Neural.model.parameters(), lr=lr)\n",
    "        \n",
    "        X = torch.tensor(self.x_train_norm.values, dtype=torch.float32)\n",
    "        Y = torch.tensor(self.y_train.values, dtype=torch.float32)\n",
    "        dataset = TensorDataset(X, Y)\n",
    "        train_loader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "        loss_history = []\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            self.Neural.model.train()\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self.Neural(x_batch)\n",
    "\n",
    "                loss = pinball_loss(y_pred, y_batch, self.Neural.quants)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            loss_history.append(loss.item())\n",
    "            if ep % 2 == 0:\n",
    "                print(f\"Epoch {ep}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    \n",
    "    def predict_neural_model(self):\n",
    "        self.Neural.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x_test_tensor = torch.tensor(self.x_test_norm.values, dtype=torch.float32)\n",
    "            y_pred = self.Neural(x_test_tensor)\n",
    "            y_pred = y_pred.numpy()\n",
    "            y_pred = y_pred.reshape(-1, len(self.targets), len(self.Neural.quants))\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    ## graph loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71e5794b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m test_forecaster\u001b[38;5;241m.\u001b[39mseparate_inputs_targets()\n\u001b[0;32m      5\u001b[0m test_forecaster\u001b[38;5;241m.\u001b[39mnormalize_data()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtest_forecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_neural_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m preds \u001b[38;5;241m=\u001b[39m test_forecaster\u001b[38;5;241m.\u001b[39mpredict_neural_model()\n\u001b[0;32m      8\u001b[0m preds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(preds\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_forecaster\u001b[38;5;241m.\u001b[39mtargets) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_forecaster\u001b[38;5;241m.\u001b[39mNeural\u001b[38;5;241m.\u001b[39mquants)), columns\u001b[38;5;241m=\u001b[39m test_forecaster\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_forecaster\u001b[38;5;241m.\u001b[39mNeural\u001b[38;5;241m.\u001b[39mquants))\n",
      "Cell \u001b[1;32mIn[74], line 74\u001b[0m, in \u001b[0;36mPredictor.train_neural_model\u001b[1;34m(self, epochs, lr)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_neural_model\u001b[39m(\u001b[38;5;28mself\u001b[39m,epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m, lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5e-5\u001b[39m):\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNeural \u001b[38;5;241m=\u001b[39m \u001b[43mNeural_Predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNeural\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m     77\u001b[0m     X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train_norm\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[1;32mIn[74], line 11\u001b[0m, in \u001b[0;36mNeural_Predictor.__init__\u001b[1;34m(self, input_size, hidden_size, output_size, quants, batch_first)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size \u001b[38;5;241m=\u001b[39m output_size\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m=\u001b[39m input_size\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      9\u001b[0m                             nn\u001b[38;5;241m.\u001b[39mLinear(input_size, hidden_size),\n\u001b[0;32m     10\u001b[0m                             nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m---> 11\u001b[0m                             \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     12\u001b[0m                             nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     13\u001b[0m                             nn\u001b[38;5;241m.\u001b[39mLinear(hidden_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, hidden_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m     14\u001b[0m                             nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     15\u001b[0m                             nn\u001b[38;5;241m.\u001b[39mLinear(hidden_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m, output_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_quants)\n\u001b[0;32m     16\u001b[0m                             )\n",
      "File \u001b[1;32mc:\\Users\\luisv\\ML-AI\\habitat\\habitat_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:106\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m--> 106\u001b[0m     torch\u001b[38;5;241m.\u001b[39mempty((out_features, in_features), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "test_forecaster = Predictor()\n",
    "test_forecaster.read_train_test_data()\n",
    "test_forecaster.preprocess_data()\n",
    "test_forecaster.separate_inputs_targets()\n",
    "test_forecaster.normalize_data()\n",
    "test_forecaster.train_neural_model()\n",
    "preds = test_forecaster.predict_neural_model()\n",
    "preds = pd.DataFrame(preds.reshape(-1, len(test_forecaster.targets) * len(test_forecaster.Neural.quants)), columns= test_forecaster.targets * len(test_forecaster.Neural.quants))\n",
    "preds.to_csv('predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
