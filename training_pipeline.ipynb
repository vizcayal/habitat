{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4cde1b",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c340c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47846d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Predictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Afeedforward neural network for multi-target forecast.\n",
    "\n",
    "    Args:\n",
    "        input_size (int): Number of input features.\n",
    "        hidden_size (int): Number of units in the hidden layers.\n",
    "        output_size (int): Number of output targets.\n",
    "        batch_first (bool): If True, input and output tensors are provided as (batch, seq, feature).\n",
    "        drop_rate (float): Dropout rate for regularization.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int = 4, hidden_size: int = 24, output_size=3, drop_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.drop_rate = drop_rate\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, int(hidden_size / 2)),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden_size / 2), output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the neural network.\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, input_size).\n",
    "        Returns:\n",
    "            Tensor: Output tensor of shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "def loss_function(preds, targets):\n",
    "    \"\"\"\n",
    "    Mean squared error loss function.\n",
    "    Args:\n",
    "        preds (Tensor): Predicted values.\n",
    "        targets (Tensor): Ground truth values.\n",
    "    Returns:\n",
    "        Tensor: Computed MSE loss.\n",
    "    \"\"\"\n",
    "    loss = F.mse_loss(preds, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predictor Class\n",
    "class Predictor:\n",
    "    \"\"\"\n",
    "    Predictor class for multi-target time series forecasting using a neural network.\n",
    "    Handles data loading, preprocessing, normalization, model training, and prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iso='random'):\n",
    "        \"\"\"\n",
    "        Predictor object constructor.\n",
    "        Args:\n",
    "            iso (str): Identifier for the ISO or region (default: 'random').\n",
    "        \"\"\"\n",
    "        self.iso = iso\n",
    "        self.predictions = {}\n",
    "        self.metrics = {}\n",
    "        self.targets = ['dalmp', 'rtlmp', 'wind_power_mw']\n",
    "        self.inputs = ['system_load_forecast', 'system_solar_forecast', 'system_wind_forecast', 'outage_forecast']\n",
    "        self.model = {}\n",
    "        self.num_scenario = 100\n",
    "\n",
    "    def read_train_test_data(self, train_file='data/train_data.parquet', test_file='data/test_data.parquet'):\n",
    "        \"\"\"\n",
    "        Read training and testing data from parquet files.\n",
    "        Args:\n",
    "            train_file (str): Path to the training data file.\n",
    "            test_file (str): Path to the testing data file.\n",
    "        \"\"\"\n",
    "        self.train_data = pd.read_parquet(train_file)\n",
    "        self.test_data = pd.read_parquet(test_file)\n",
    "\n",
    "        # Save as CSV for inspection/debugging\n",
    "        self.train_data.to_csv('train_data.csv')\n",
    "        self.test_data.to_csv('test_data.csv')\n",
    "\n",
    "    def add_lagged_features(self):\n",
    "        \"\"\"\n",
    "        Add lagged features to the training and testing data.\n",
    "        \"\"\"\n",
    "        # Create lagged features for the target variables\n",
    "        for target in self.targets:\n",
    "            for i in range(1):\n",
    "                self.train_data[f'{target}_lag_{i}'] = self.train_data[target].shift(i)\n",
    "                self.test_data[f'{target}_lag_{i}'] = self.test_data[target].shift(i)\n",
    "\n",
    "        # Drop rows with NaN values created by lagging\n",
    "        self.train_data = self.train_data.dropna()\n",
    "        self.test_data = self.test_data.dropna()\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        Preprocess the data by removing NaNs and duplicates.\n",
    "        \"\"\"\n",
    "        # Remove rows with any NaN values\n",
    "        self.train_data = self.train_data.dropna()\n",
    "        self.test_data = self.test_data.dropna()\n",
    "        # Remove duplicate rows\n",
    "        self.train_data = self.train_data.drop_duplicates()\n",
    "        self.test_data = self.test_data.drop_duplicates()\n",
    "\n",
    "    def separate_inputs_targets(self):\n",
    "        \"\"\"\n",
    "        Separate input features and target variables for training and testing.\n",
    "        \"\"\"\n",
    "        self.x_train = self.train_data[self.inputs]\n",
    "        self.y_train = self.train_data[self.targets]\n",
    "        self.x_test = self.test_data[self.inputs]\n",
    "\n",
    "    def normalize_data(self):\n",
    "        \"\"\"\n",
    "        Normalize the input and target data using StandardScaler.\n",
    "        \"\"\"\n",
    "        self.scaler_input = StandardScaler()\n",
    "        self.scaler_target = StandardScaler()\n",
    "        self.x_train_norm = pd.DataFrame(self.scaler_input.fit_transform(self.x_train), columns=self.x_train.columns)\n",
    "        self.x_test_norm = pd.DataFrame(self.scaler_input.transform(self.x_test), columns=self.x_test.columns)\n",
    "        self.y_train_norm = pd.DataFrame(self.scaler_target.fit_transform(self.y_train), columns=self.y_train.columns)\n",
    "        self.y_train_norm.to_csv('y_train_norm.csv')\n",
    "\n",
    "    def calc_mean_std(self):\n",
    "        \"\"\"\n",
    "        Calculate the mean and standard deviation of the target variables.\n",
    "        \"\"\"\n",
    "        self.target_mean = self.y_train.mean()\n",
    "        self.target_std = self.y_train.std()\n",
    "        self.target_mean = self.target_mean.values\n",
    "        self.target_std = self.target_std.values\n",
    "\n",
    "    def calc_target_cov(self):\n",
    "        \"\"\"\n",
    "        Calculate the covariance matrix of the normalized target variables.\n",
    "        \"\"\"\n",
    "        self.target_cov = self.y_train_norm.cov()\n",
    "        self.target_cov = self.target_cov.values\n",
    "\n",
    "    def train_neural_model(self, epochs=1, lr=3e-5):\n",
    "        \"\"\"\n",
    "        Train the neural network model on the training data.\n",
    "        Args:\n",
    "            epochs (int): Number of training epochs.\n",
    "            lr (float): Learning rate for the optimizer.\n",
    "        \"\"\"\n",
    "        self.Neural = Neural_Predictor()\n",
    "        optimizer = torch.optim.Adam(self.Neural.model.parameters(), lr=lr)\n",
    "        X = torch.tensor(self.x_train_norm.values, dtype=torch.float32)\n",
    "        Y = torch.tensor(self.y_train_norm.values, dtype=torch.float32)\n",
    "        dataset = TensorDataset(X, Y)\n",
    "        train_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        loss_history = []\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            self.Neural.model.train()\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self.Neural(x_batch)\n",
    "                loss = loss_function(y_pred, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            loss_history.append(loss.item())\n",
    "            if ep % 2 == 0:\n",
    "                print(f\"Epoch {ep}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    def predict_neural_model(self):\n",
    "        \"\"\"\n",
    "        Generate predictions using the trained neural network model for multiple scenarios.\n",
    "\n",
    "        This method sets the model to training mode (for dropout, if used), then iterates over the number of scenarios,\n",
    "        generating predictions for each scenario. The predictions are inverse-transformed to the original scale and\n",
    "        stored in a dictionary, with each scenario's predictions as a DataFrame. All scenario DataFrames are then\n",
    "        concatenated along the columns to form the final predictions DataFrame.\n",
    "        Returns:\n",
    "            dict: A dictionary where each key is a scenario index and each value is a DataFrame of predictions for that scenario.\n",
    "        \"\"\"\n",
    "        self.Neural.model.train()\n",
    "        y_pred = {}\n",
    "        self.predictions = pd.DataFrame()\n",
    "        with torch.no_grad():\n",
    "            x_test_tensor = torch.tensor(self.x_test_norm.values, dtype=torch.float32)\n",
    "            for i in range(self.num_scenario):\n",
    "                scenario_cols = [t+'_'+str(i) for t in self.targets]\n",
    "                preds_norm = self.Neural(x_test_tensor).numpy()\n",
    "                preds = self.scaler_target.inverse_transform(preds_norm)\n",
    "                y_pred[i] = pd.DataFrame(preds, columns = scenario_cols, index = self.x_test.index)\n",
    "            self.predictions = pd.concat(y_pred, axis=1)\n",
    "   \n",
    "        return self.predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Loss: 0.3765218257904053\n",
      "                            0                                      1   \\\n",
      "                       dalmp_0     rtlmp_0 wind_power_mw_0    dalmp_1   \n",
      "2024-01-01 00:00:00  37.916378   94.366066       56.909760  42.667450   \n",
      "2024-01-01 01:00:00  44.751373  115.706169       53.558567  46.650566   \n",
      "2024-01-01 02:00:00  33.898396  100.305801       55.517666  53.650032   \n",
      "2024-01-01 03:00:00  49.100170  121.792473       51.034256  50.120289   \n",
      "2024-01-01 04:00:00  39.286140  103.594429       57.062607  50.298328   \n",
      "...                        ...         ...             ...        ...   \n",
      "2024-01-30 19:00:00  67.535812  107.601921       51.142265  77.745789   \n",
      "2024-01-30 20:00:00  56.074043  123.036407       52.004753  80.737289   \n",
      "2024-01-30 21:00:00  59.040596  114.959511       51.675560  51.421848   \n",
      "2024-01-30 22:00:00  35.268898  103.779907       56.151901  40.675575   \n",
      "2024-01-30 23:00:00  38.593079   98.925110       55.659004  37.850677   \n",
      "\n",
      "                                                        2               \\\n",
      "                        rtlmp_1 wind_power_mw_1    dalmp_2     rtlmp_2   \n",
      "2024-01-01 00:00:00   99.423058       55.525013  45.842106  109.113251   \n",
      "2024-01-01 01:00:00  114.673500       53.098610  45.859726   94.754425   \n",
      "2024-01-01 02:00:00  103.646683       49.645351  39.643887  108.115593   \n",
      "2024-01-01 03:00:00  107.360062       50.272663  38.264214   91.299957   \n",
      "2024-01-01 04:00:00  100.667038       49.695156  37.204102   93.213303   \n",
      "...                         ...             ...        ...         ...   \n",
      "2024-01-30 19:00:00  123.360428       45.832447  80.999100  127.242363   \n",
      "2024-01-30 20:00:00  123.444122       45.596088  71.145004  116.383667   \n",
      "2024-01-30 21:00:00  103.454552       54.465702  62.545815  117.008476   \n",
      "2024-01-30 22:00:00   94.210075       56.724918  45.734520   91.459198   \n",
      "2024-01-30 23:00:00  100.098740       56.384041  42.070019   96.069946   \n",
      "\n",
      "                                            3   ...               96  \\\n",
      "                    wind_power_mw_2    dalmp_3  ... wind_power_mw_96   \n",
      "2024-01-01 00:00:00       50.162170  43.170620  ...        55.180889   \n",
      "2024-01-01 01:00:00       50.185417  32.591770  ...        56.301685   \n",
      "2024-01-01 02:00:00       50.061504  39.787064  ...        49.910641   \n",
      "2024-01-01 03:00:00       56.114742  46.126095  ...        57.815155   \n",
      "2024-01-01 04:00:00       56.834911  35.747936  ...        55.438313   \n",
      "...                             ...        ...  ...              ...   \n",
      "2024-01-30 19:00:00       45.857441  70.046486  ...        47.434170   \n",
      "2024-01-30 20:00:00       47.887997  63.259369  ...        49.577713   \n",
      "2024-01-30 21:00:00       51.110538  65.518005  ...        44.375099   \n",
      "2024-01-30 22:00:00       50.508980  34.808346  ...        58.065086   \n",
      "2024-01-30 23:00:00       55.251194  41.797462  ...        53.375431   \n",
      "\n",
      "                            97                                      98  \\\n",
      "                      dalmp_97    rtlmp_97 wind_power_mw_97   dalmp_98   \n",
      "2024-01-01 00:00:00  49.321144  106.857452        50.169712  40.981911   \n",
      "2024-01-01 01:00:00  42.001781  104.435310        57.334869  39.000385   \n",
      "2024-01-01 02:00:00  37.952377   95.059929        54.655426  47.498672   \n",
      "2024-01-01 03:00:00  51.541637  108.426414        52.474197  57.761303   \n",
      "2024-01-01 04:00:00  54.369072  103.075577        49.400372  47.710766   \n",
      "...                        ...         ...              ...        ...   \n",
      "2024-01-30 19:00:00  84.670235  133.379883        42.366451  68.586632   \n",
      "2024-01-30 20:00:00  60.713535   96.383720        51.797276  66.242294   \n",
      "2024-01-30 21:00:00  41.934624  107.561569        57.540813  64.633614   \n",
      "2024-01-30 22:00:00  37.714787  102.069939        58.445286  43.298141   \n",
      "2024-01-30 23:00:00  39.671497   99.330666        54.884212  41.042641   \n",
      "\n",
      "                                                         99              \\\n",
      "                       rtlmp_98 wind_power_mw_98   dalmp_99    rtlmp_99   \n",
      "2024-01-01 00:00:00   97.315201        57.859894  40.242088   98.561165   \n",
      "2024-01-01 01:00:00   91.451111        56.732445  45.387409  108.769814   \n",
      "2024-01-01 02:00:00  101.145844        54.271450  39.802876   95.182373   \n",
      "2024-01-01 03:00:00  107.949081        50.806416  36.555965  115.656975   \n",
      "2024-01-01 04:00:00  106.131020        54.086258  42.067303   95.674210   \n",
      "...                         ...              ...        ...         ...   \n",
      "2024-01-30 19:00:00  119.368172        49.843834  46.107468  103.676590   \n",
      "2024-01-30 20:00:00  125.375214        47.433922  69.913788  111.158913   \n",
      "2024-01-30 21:00:00  120.837273        50.188808  69.976158  111.381317   \n",
      "2024-01-30 22:00:00  104.524437        55.988712  56.413818  105.181702   \n",
      "2024-01-30 23:00:00   97.630188        52.377605  53.166824  112.589447   \n",
      "\n",
      "                                      \n",
      "                    wind_power_mw_99  \n",
      "2024-01-01 00:00:00        54.993752  \n",
      "2024-01-01 01:00:00        55.467617  \n",
      "2024-01-01 02:00:00        56.132542  \n",
      "2024-01-01 03:00:00        52.217110  \n",
      "2024-01-01 04:00:00        55.268810  \n",
      "...                              ...  \n",
      "2024-01-30 19:00:00        55.503407  \n",
      "2024-01-30 20:00:00        49.115620  \n",
      "2024-01-30 21:00:00        45.983204  \n",
      "2024-01-30 22:00:00        51.862198  \n",
      "2024-01-30 23:00:00        50.835419  \n",
      "\n",
      "[720 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Predictor class for multi-target time series forecasting\n",
    "test_forecaster = Predictor()\n",
    "\n",
    "# Read training and testing data from parquet files\n",
    "test_forecaster.read_train_test_data()\n",
    "\n",
    "# Preprocess the data by removing NaNs and duplicates\n",
    "test_forecaster.preprocess_data()\n",
    "\n",
    "# Separate input features and target variables for training and testing\n",
    "test_forecaster.separate_inputs_targets()\n",
    "\n",
    "# Normalize the input and target data using StandardScaler\n",
    "test_forecaster.normalize_data()\n",
    "\n",
    "# Calculate the covariance matrix of the normalized target variables\n",
    "test_forecaster.calc_target_cov()\n",
    "\n",
    "# Train the neural network model on the training data\n",
    "test_forecaster.train_neural_model()\n",
    "\n",
    "# Generate predictions using the trained neural network model for multiple scenarios\n",
    "preds = test_forecaster.predict_neural_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
